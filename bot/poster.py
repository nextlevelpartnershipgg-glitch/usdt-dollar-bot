# bot/poster.py
import os, io, re, random, time, json, hashlib, urllib.parse
from datetime import datetime
import requests, feedparser
from PIL import Image, ImageDraw, ImageFont, ImageOps

# ================== –ë–ê–ó–û–í–´–ô –ö–û–ù–§–ò–ì ==================
BOT_TOKEN   = os.getenv("BOT_TOKEN", "").strip()
CHANNEL_ID  = os.getenv("CHANNEL_ID", "").strip()             # –Ω–∞–ø—Ä–∏–º–µ—Ä: @usdtdollarm
MAX_POSTS_PER_RUN   = int(os.getenv("MAX_POSTS_PER_RUN", "1"))
HTTP_TIMEOUT        = 12
LOGO_PATH           = os.getenv("LOGO_PATH", "bot/logo.png")
LOW_QUALITY_MIN_LEN = int(os.getenv("LOW_QUALITY_MIN_LEN", "200"))
ALLOW_BACKLOG       = os.getenv("ALLOW_BACKLOG", "1") == "1"

STATE_PATH = "data/state.json"

# –¢–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–†–ò–ê –Ω–µ –≤–∫–ª—é—á–∞–µ–º)
RSS_FEEDS = [
    "https://rssexport.rbc.ru/rbcnews/news/30/full.rss",
    "https://rssexport.rbc.ru/rbcnews/economics/30/full.rss",
    "https://rssexport.rbc.ru/rbcnews/finance/30/full.rss",
    "https://www.kommersant.ru/RSS/news.xml",
    "https://www.kommersant.ru/RSS/economics.xml",
    "https://www.kommersant.ru/RSS/finance.xml",
    "https://lenta.ru/rss/news",
    "https://lenta.ru/rss/economics",
    "https://lenta.ru/rss/russia",
    "https://lenta.ru/rss/world",
    "https://tass.ru/rss/v2.xml",
    "https://tass.ru/economy/rss",
    "https://tass.ru/politika/rss",
    "https://www.vedomosti.ru/rss/news",
    "https://www.interfax.ru/rss.asp",
    "https://www.gazeta.ru/export/rss/first.xml",
    "https://www.gazeta.ru/export/rss/business.xml",
    "https://iz.ru/xml/rss/all.xml",
    "https://www.finmarket.ru/rss/news.asp",
    "https://www.banki.ru/xml/news.rss",
    "https://1prime.ru/export/rss2/index.xml",
    "https://rg.ru/tema/ekonomika/rss.xml",
    "https://www.forbes.ru/newrss.xml",
    "https://www.mskagency.ru/rss/all",
    "https://www.ng.ru/rss/",
    "https://www.mk.ru/rss/finance/index.xml",
    "https://www.fontanka.ru/fontanka.rss",
    "https://minfin.gov.ru/ru/press-center/?rss=Y",
    "https://cbr.ru/StaticHtml/Rss/Press",
    "https://www.moex.com/Export/MRSS/News",
]

# ================== –£–¢–ò–õ–ò–¢–´ –°–û–°–¢–û–Ø–ù–ò–Ø ==================
def _norm_url(u: str) -> str:
    if not u: return ""
    p = urllib.parse.urlsplit(u)
    q = urllib.parse.parse_qsl(p.query, keep_blank_values=True)
    q = [(k, v) for (k, v) in q if not k.lower().startswith(("utm_","yclid","gclid","fbclid"))]
    return urllib.parse.urlunsplit((p.scheme, p.netloc.lower(), p.path, urllib.parse.urlencode(q), ""))

def _uid_for(link: str, title: str) -> str:
    key = _norm_url(link) or (title or "").strip().lower()
    return hashlib.sha256(key.encode("utf-8")).hexdigest()

def _load_state():
    try:
        with open(STATE_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {"posted": []}

def _save_state(state):
    os.makedirs(os.path.dirname(STATE_PATH), exist_ok=True)
    with open(STATE_PATH, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

# ================== –¢–ï–ö–°–¢: –û–ë–©–ï–ï ==================
def detect_lang(text: str) -> str:
    return "ru" if re.search(r"[–ê-–Ø–∞-—è–Å—ë]", text or "") else "non-ru"

def split_sentences(text: str):
    text = re.sub(r"\s+", " ", (text or "").strip())
    if not text: return []
    parts = re.split(r"(?<=[\.\!\?])\s+", text)
    parts = [re.sub(r"&nbsp;|&mdash;", " ", p) for p in parts]
    return [p.strip() for p in parts if p.strip()]

def _smart_capitalize(s: str) -> str:
    s = re.sub(r"\s+", " ", (s or "").strip())
    if not s: return s
    m = re.search(r"[A-Za-z–ê-–Ø–∞-—è–Å—ë]", s)
    if not m: return s
    i = m.start()
    return s[:i] + s[i].upper() + s[i+1:]

def _remove_unmatched(s: str, open_ch: str, close_ch: str) -> str:
    bal, out = 0, []
    for ch in s:
        if ch == open_ch:
            bal += 1; out.append(ch)
        elif ch == close_ch:
            if bal == 0: continue
            bal -= 1; out.append(ch)
        else:
            out.append(ch)
    if bal > 0: out.append(close_ch * bal)
    return "".join(out)

def _balance_brackets_and_quotes(s: str) -> str:
    s = _remove_unmatched(s, "(", ")")
    s = _remove_unmatched(s, "[", "]")
    opens = s.count("¬´"); closes = s.count("¬ª")
    if closes > opens:
        need = opens; buf=[]; seen=0
        for ch in s:
            if ch == "¬ª":
                if seen >= need: continue
                seen += 1
            buf.append(ch)
        s = "".join(buf)
    elif opens > closes:
        s += "¬ª" * (opens - closes)
    return s

def tidy_paragraph(p: str) -> str:
    p = (p or "").strip()
    if not p: return p
    p = _balance_brackets_and_quotes(p)
    p = _smart_capitalize(p)
    p = re.sub(r"\s+([,.:;!?])", r"\1", p)
    p = re.sub(r"\s+", " ", p).strip()
    return p

def _normalize_for_cmp(s: str) -> str:
    s = re.sub(r"&nbsp;|&mdash;", " ", s or "")
    s = re.sub(r"\s+", " ", s).strip().lower()
    s = re.sub(r"[¬´¬ª\"'`‚Äô]", "", s)
    return s

def dedupe_sentences(sents, title=""):
    seen = set()
    norm_title = _normalize_for_cmp(title)
    out = []
    for s in sents:
        ns = _normalize_for_cmp(s)
        if not ns: continue
        if ns == norm_title: continue
        if ns in seen: continue
        seen.add(ns)
        out.append(s.strip())
    return out

RU_STOP = set("—ç—Ç–æ —ç—Ç–æ—Ç —ç—Ç–∞ —ç—Ç–∏ —Ç–∞–∫–æ–π —Ç–∞–∫–∞—è —Ç–∞–∫–æ–µ —Ç–∞–∫–∏–µ –∫–∞–∫ –ø–æ –ø—Ä–∏ –ø—Ä–æ –¥–ª—è –Ω–∞ –∏–∑ –æ—Ç –∏–ª–∏ –ª–∏–±–æ –µ—â—ë —É–∂–µ –µ—Å–ª–∏ –∫–æ–≥–¥–∞ –∫—É–¥–∞ –≥–¥–µ —á–µ–º —á—Ç–æ —á—Ç–æ–±—ã –∏ –≤ –≤–æ –∞ –Ω–æ –∂–µ —Ç–æ—Ç —Ç–∞ —Ç–æ —Ç–µ –∫ —Å –æ –æ–±".split())

def extract_tags_source(text, min_tags=3, max_tags=5):
    words = re.findall(r"[A-Za-z–ê-–Ø–∞-—è–Å—ë]{3,}", (text or "").lower())
    words = [re.sub(r"[^a-z–∞-—è—ë]", "", w) for w in words]
    freq = {}
    for w in words:
        if w and w not in RU_STOP:
            freq[w] = freq.get(w, 0) + 1
    top = [w for w, _ in sorted(freq.items(), key=lambda x: -x[1])]
    tags = []
    for w in top:
        if len(tags) >= max_tags: break
        if w not in tags: tags.append(w)
    while len(tags) < min_tags and "—Ä—ã–Ω–∫–∏" not in tags: tags.append("—Ä—ã–Ω–∫–∏")
    return "||" + " ".join("#"+t for t in tags[:max_tags]) + "||"

# ================== –í–ò–ó–£–ê–õ ==================
PALETTES_GENERAL = [((28,42,74),(12,18,30)), ((18,64,96),(8,24,36)), ((84,32,68),(18,12,28))]
PALETTES_ECON    = [((6,86,70),(4,40,36)), ((16,112,84),(8,36,28))]
PALETTES_CRYPTO  = [((36,44,84),(16,18,40)), ((32,110,92),(14,28,32))]
PALETTES_POLIT   = [((98,36,36),(24,12,14)), ((52,22,90),(16,12,34))]
PALETTES_ENERGY  = [((124,72,16),(22,16,10)), ((88,46,18),(16,12,10))]
PALETTES_TRAGIC  = [((40,40,40),(8,8,10)), ((54,54,64),(14,14,20))]

def pick_palette(title_summary: str):
    t = (title_summary or "").lower()
    if any(k in t for k in ["–≤–∑—Ä—ã–≤","–∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ","–∞–≤–∞—Ä","–ø–æ–≥–∏–±","–±–æ–º–±","—Ç–µ—Ä–∞–∫—Ç","—à—Ç–æ—Ä–º","—É—Ä–∞–≥–∞"]):
        base = PALETTES_TRAGIC
    elif any(k in t for k in ["–Ω–µ—Ñ—Ç—å","–≥–∞–∑","opec","–±—Ä–µ–Ω—Ç","—ç–Ω–µ—Ä–≥–∏","—É–≥–æ–ª—å","—ç–ª–µ–∫—Ç—Ä–æ"]):
        base = PALETTES_ENERGY
    elif any(k in t for k in ["—Å—Ç–∞–≤–∫","—Ü–±","–∏–Ω—Ñ–ª—è—Ü","cpi","ppi","–Ω–∞–ª–æ–≥","–±—é–¥–∂–µ—Ç","–≤–≤–ø"]):
        base = PALETTES_ECON
    elif any(k in t for k in ["–∫—Ä–∏–ø—Ç","–±–∏—Ç–∫–æ–∏–Ω","bitcoin","eth","—Å—Ç–µ–π–±–ª","usdt"]):
        base = PALETTES_CRYPTO
    elif any(k in t for k in ["–≤—ã–±–æ—Ä—ã","—Å–∞–Ω–∫—Ü","–ø–∞—Ä–ª–∞–º–µ–Ω—Ç","–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç","–º–∏–¥"]):
        base = PALETTES_POLIT
    else:
        base = PALETTES_GENERAL
    return random.choice(base)

def _boost(c, k=1.3): return tuple(max(0, min(255, int(v*k))) for v in c)

def generate_gradient(size=(1080, 540), title_summary: str = ""):
    W,H = size
    top, bottom = pick_palette(title_summary)
    top, bottom = _boost(top,1.3), _boost(bottom,1.3)
    img = Image.new("RGB", (W,H))
    d = ImageDraw.Draw(img)
    for y in range(H):
        t = y/(H-1)
        r = int(top[0]*(1-t) + bottom[0]*t)
        g = int(top[1]*(1-t) + bottom[1]*t)
        b = int(top[2]*(1-t) + bottom[2]*t)
        d.line([(0,y),(W,y)], fill=(r,g,b))
    overlay = Image.new("RGBA",(W,H),(0,0,0,0))
    od = ImageDraw.Draw(overlay)
    step = 20
    for x in range(-H, W, step):
        od.line([(x,0),(x+H,H)], fill=(255,255,255,18), width=1)
    img = Image.alpha_composite(img.convert("RGBA"), overlay).convert("RGB")
    return img

def _font(path: str, size: int):
    try: return ImageFont.truetype(path, size)
    except Exception: return ImageFont.load_default()

def wrap_by_width(draw: ImageDraw.ImageDraw, text: str, font: ImageFont.FreeTypeFont, max_w: int, max_lines=5):
    words = (text or "").split()
    lines, cur = [], ""
    for w in words:
        test = (cur + " " + w).strip()
        if draw.textlength(test, font=font) <= max_w:
            cur = test
        else:
            if cur:
                lines.append(cur)
                if len(lines) >= max_lines: return lines
            cur = w
    if cur and len(lines) < max_lines: lines.append(cur)
    return lines

def _safe_open_logo():
    if not os.path.exists(LOGO_PATH): return None
    try:
        img = Image.open(LOGO_PATH).convert("RGBA")
        size = min(img.size)
        img = ImageOps.fit(img, (size, size), method=Image.LANCZOS)
        mask = Image.new("L", (size, size), 0)
        ImageDraw.Draw(mask).ellipse((0,0,size,size), fill=255)
        img.putalpha(mask)
        return img
    except Exception:
        return None

def _draw_fallback_coin(size=72):
    img = Image.new("RGBA", (size,size), (0,0,0,0))
    d = ImageDraw.Draw(img)
    d.ellipse((0,0,size,size), fill=(210,210,210,255))
    d.ellipse((6,6,size-6,size-6), fill=(235,235,235,255))
    font = _font("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", size//2)
    w = d.textlength("$", font=font)
    d.text(((size-w)/2, size*0.24), "$", font=font, fill=(60,60,60,255))
    return img

def draw_card(title: str, source_domain: str, post_stamp: str, themed_hint: str = "") -> io.BytesIO:
    W,H = 1080, 540
    base = generate_gradient((W,H), title_summary=themed_hint).convert("RGBA")

    header = Image.new("RGBA", (W, 84), (0,0,0,80))
    base.alpha_composite(header, (0,0))

    d = ImageDraw.Draw(base)
    font_bold = _font("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 36)
    font_reg  = _font("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 22)

    logo = _safe_open_logo() or _draw_fallback_coin(72)
    base.alpha_composite(logo, (36, 6))

    d.text((120, 22), "USDT=Dollar", font=font_bold, fill=(255,255,255,255))
    right = f"–ø–æ—Å—Ç: {post_stamp}"
    d.text((W-36-d.textlength(right,font=font_reg), 28), right, font=font_reg, fill=(255,255,255,230))

    pad = Image.new("RGBA", (W-72, H-84-86), (0,0,0,110))
    base.alpha_composite(pad, (36, 100))

    title = (title or "").strip()
    box_x, box_y = 64, 124
    box_w, box_h = W-2*box_x, H- box_y - 132
    size = 64; lines = []
    while size >= 28:
        f = _font("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", size)
        lines = wrap_by_width(d, title, f, box_w, max_lines=4)
        line_h = f.getbbox("Ag")[3]
        total_h = len(lines)*line_h + (len(lines)-1)*8
        if lines and total_h <= box_h: break
        size -= 2
    y = box_y
    for ln in lines:
        d.text((box_x+2, y+2), ln, font=f, fill=(0,0,0,120))
        d.text((box_x, y), ln, font=f, fill=(255,255,255,255))
        y += f.getbbox("Ag")[3] + 8

    footer_h = 70
    footer = Image.new("RGBA", (W, footer_h), (0,0,0,84))
    base.alpha_composite(footer, (0, H-footer_h))
    d = ImageDraw.Draw(base)
    d.text((36, H-48), f"source: {source_domain}", font=font_reg, fill=(230,230,230,230))

    bio = io.BytesIO()
    base.convert("RGB").save(bio, format="PNG", optimize=True)
    bio.seek(0)
    return bio

# ================== –ê–ì–†–ï–°–°–ò–í–ù–´–ô –ü–ï–†–ï–§–†–ê–ó ==================
# –°–∏–Ω–æ–Ω–∏–º—ã + —Ñ—Ä–∞–∑—ã. –î–æ–±–∞–≤–ª—è—Ç—å –º–æ–∂–Ω–æ —Å–º–µ–ª–æ ‚Äî —Ä–µ–≥–∏—Å—Ç—Ä —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è.
SYN_MAP = {
    "—Å–æ–æ–±—â–∏–ª":["–∑–∞—è–≤–∏–ª","—É—Ç–æ—á–Ω–∏–ª","–ø—Ä–æ–∏–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–ª","–ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª","—Ä–∞—Å—Å–∫–∞–∑–∞–ª"],
    "—Å–æ–æ–±—â–∏–ª–∞":["–∑–∞—è–≤–∏–ª–∞","—É—Ç–æ—á–Ω–∏–ª–∞","–ø—Ä–æ–∏–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–ª–∞","–ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª–∞","—Ä–∞—Å—Å–∫–∞–∑–∞–ª–∞"],
    "—Å–æ–æ–±—â–∏–ª–∏":["–∑–∞—è–≤–∏–ª–∏","—É—Ç–æ—á–Ω–∏–ª–∏","–ø—Ä–æ–∏–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–ª–∏","–ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª–∏","—Ä–∞—Å—Å–∫–∞–∑–∞–ª–∏"],
    "–∑–∞—è–≤–∏–ª":["—Å–æ–æ–±—â–∏–ª","–æ—Ç–º–µ—Ç–∏–ª","–ø–æ–¥—á–µ—Ä–∫–Ω—É–ª","–∫–æ–Ω—Å—Ç–∞—Ç–∏—Ä–æ–≤–∞–ª"],
    "–∑–∞—è–≤–∏–ª–∞":["—Å–æ–æ–±—â–∏–ª–∞","–æ—Ç–º–µ—Ç–∏–ª–∞","–ø–æ–¥—á–µ—Ä–∫–Ω—É–ª–∞","–∫–æ–Ω—Å—Ç–∞—Ç–∏—Ä–æ–≤–∞–ª–∞"],
    "–∑–∞—è–≤–∏–ª–∏":["—Å–æ–æ–±—â–∏–ª–∏","–æ—Ç–º–µ—Ç–∏–ª–∏","–ø–æ–¥—á–µ—Ä–∫–Ω—É–ª–∏","–∫–æ–Ω—Å—Ç–∞—Ç–∏—Ä–æ–≤–∞–ª–∏"],
    "—Ä–∞–Ω–µ–µ":["–ø—Ä–µ–∂–¥–µ","–¥–æ —ç—Ç–æ–≥–æ","—Ä–∞–Ω—å—à–µ"],
    "—Ç–∞–∫–∂–µ":["–∫—Ä–æ–º–µ —Ç–æ–≥–æ","–≤–¥–æ–±–∞–≤–æ–∫","–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ"],
    "–æ–¥–Ω–∞–∫–æ":["–ø—Ä–∏ —ç—Ç–æ–º","–≤–º–µ—Å—Ç–µ —Å —Ç–µ–º","—Ç–µ–º –Ω–µ –º–µ–Ω–µ–µ"],
    "–∏–∑-–∑–∞":["–≤—Å–ª–µ–¥—Å—Ç–≤–∏–µ","–ø–æ –ø—Ä–∏—á–∏–Ω–µ"],
    "–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ":["–≤ –∏—Ç–æ–≥–µ","–∫–∞–∫ —Å–ª–µ–¥—Å—Ç–≤–∏–µ"],
    "–≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏":["–≤ —Ç–æ–º —á–∏—Å–ª–µ","–Ω–∞–ø—Ä–∏–º–µ—Ä"],
    "–æ–∂–∏–¥–∞–µ—Ç—Å—è":["–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è","–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ—Ç—Å—è"],
    "–ø–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è":["–Ω–∞–º–µ—á–∞–µ—Ç—Å—è","—Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è"],
    "–ø–æ–≤—ã—à–µ–Ω–∏–µ":["—Ä–æ—Å—Ç","—É–≤–µ–ª–∏—á–µ–Ω–∏–µ"],
    "—Å–Ω–∏–∂–µ–Ω–∏–µ":["–ø–∞–¥–µ–Ω–∏–µ","—Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ","–ø—Ä–æ—Å–∞–¥–∫–∞"],
    "—Ä–æ—Å—Ç":["—É–≤–µ–ª–∏—á–µ–Ω–∏–µ","–ø–æ–¥—ä—ë–º"],
    "–ø–∞–¥–µ–Ω–∏–µ":["—Å–Ω–∏–∂–µ–Ω–∏–µ","–ø—Ä–æ—Å–∞–¥–∫–∞"],
    "–ø–æ–¥–¥–µ—Ä–∂–∫–∞":["—Å–æ–¥–µ–π—Å—Ç–≤–∏–µ","–ø–æ–¥–ø–∏—Ç–∫–∞"],
    "—Å–∞–Ω–∫—Ü–∏–∏":["–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è","—Ä–µ—Å—Ç—Ä–∏–∫—Ü–∏–∏"],
    "–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ":["–ø–ª—é—Å","–∫—Ä–æ–º–µ —Ç–æ–≥–æ"],
    "–ø—Ä–∏—á–∏–Ω–∞":["—Ñ–∞–∫—Ç–æ—Ä","–æ—Å–Ω–æ–≤–∞–Ω–∏–µ"],
    "—Å—Ä–æ–∫–∏":["–¥–µ–¥–ª–∞–π–Ω—ã","–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏"],
    "—Ä–µ—à–µ–Ω–∏–µ":["—à–∞–≥","–º–µ—Ä—ã","–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞"],
}

PHRASES = [
    (r"\b–≤\s+–Ω–∞—Å—Ç–æ—è—â–µ–µ\s+–≤—Ä–µ–º—è\b","—Å–µ–π—á–∞—Å"),
    (r"\b–Ω–∞\s+–¥–∞–Ω–Ω—ã–π\s+–º–æ–º–µ–Ω—Ç\b","—Å–µ–π—á–∞—Å"),
    (r"\b–≤\s+–±–ª–∏–∂–∞–π—à–µ–µ\s+–≤—Ä–µ–º—è\b","—Å–∫–æ—Ä–æ"),
    (r"\b–≤\s+—Ç–æ–º\s+—á–∏—Å–ª–µ\b","–≤–∫–ª—é—á–∞—è"),
    (r"\b—Å–æ–≥–ª–∞—Å–Ω–æ\s+–¥–∞–Ω–Ω—ã–º\b","–ø–æ –¥–∞–Ω–Ω—ã–º"),
    (r"\b—Å–æ–æ–±—â–∞–µ—Ç—Å—è,\s+—á—Ç–æ\b","–ø–æ —Å–æ–æ–±—â–µ–Ω–∏—è–º,"),
    (r"\b–∫–∞–∫\s+—É—Ç–≤–µ—Ä–∂–¥–∞—é—Ç\b","–ø–æ –æ—Ü–µ–Ω–∫–∞–º"),
]

def _keep_case(src: str, repl: str) -> str:
    if src.isupper(): return repl.upper()
    if src[:1].isupper(): return repl[:1].upper() + repl[1:]
    return repl

def _swap_clauses(sent: str) -> str:
    """
    –ü—Ä–æ—Å—Ç–∞—è –∏–Ω–≤–µ—Ä—Å–∏—è: –ø–µ—Ä–µ–Ω–æ—Å–∏–º –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤–µ–Ω–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –≤ –Ω–∞—á–∞–ª–æ/–∫–æ–Ω–µ—Ü.
    """
    s = sent
    # –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å "–ø–æ –¥–∞–Ω–Ω—ã–º/—Å–æ–æ–±—â–∞–µ—Ç—Å—è/–∫–∞–∫ —É—Ç–æ—á–Ω–∏–ª–∏"
    s = re.sub(r"(.+?),\s+(–ø–æ –¥–∞–Ω–Ω—ã–º|–ø–æ —Å–æ–æ–±—â–µ–Ω–∏—è–º|–∫–∞–∫ —É—Ç–æ—á–Ω–∏–ª–∏|–∫–∞–∫ –∑–∞—è–≤–∏–ª–∏)\s+([^,]+)", r"\2 \3, \1", s, flags=re.IGNORECASE)
    # –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º/–º–µ—Å—Ç–æ–º
    s = re.sub(r"(–í\s+\S.+?)\s+(\w.+)", r"\2. \1", s) if random.random()<0.35 else s
    return s

def paraphrase_ru(text: str, target_ratio: float = 0.9) -> str:
    """
    –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –ø–µ—Ä–µ—Ñ—Ä–∞–∑ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å–º—ã—Å–ª–∞.
    - –ú–∞—Å—Å–æ–≤–∞—è –∑–∞–º–µ–Ω–∞ —Å–ª–æ–≤
    - –ò–Ω–≤–µ—Ä—Å–∏—è –ø—Ä–æ—Å—Ç—ã—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
    - –°–±–æ—Ä–∫–∞ –Ω–æ–≤–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
    """
    if not text: return text
    original = text

    # —Ñ—Ä–∞–∑—ã —Ü–µ–ª–∏–∫–æ–º
    for pat, repl in PHRASES:
        text = re.sub(pat, repl, text, flags=re.IGNORECASE)

    # –ø–æ–±—É–∫–≤–µ–Ω–Ω–∞—è –∑–∞–º–µ–Ω–∞ —Å–ª–æ–≤ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –ø—Ä–æ–±–µ–ª–æ–≤/–ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
    words = text.split()
    idxs = [i for i,w in enumerate(words) if w.lower().strip(".,!?;:") in SYN_MAP]
    random.shuffle(idxs)
    limit = max(1, int(len(idxs)*target_ratio))
    done = 0
    puncts = ".,!?;:"
    for i in idxs:
        if done >= limit: break
        raw = words[i]
        core = raw.rstrip(puncts)
        tail = raw[len(core):]
        key = core.lower()
        opts = SYN_MAP.get(key)
        if not opts: continue
        repl = _keep_case(core, random.choice(opts))
        words[i] = repl + tail
        done += 1
    text = " ".join(words)

    # —Ä–∞–±–æ—Ç–∞ –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º ‚Äî –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∏/—Å–∫–ª–µ–π–∫–∏
    sents = split_sentences(text)
    out = []
    for s in sents:
        s = s.strip()
        if not s: continue
        if random.random() < 0.7:
            s = _swap_clauses(s)
        # –ø–∞—Å—Å–∏–≤ ‚Üî –∞–∫—Ç–∏–≤ (–ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞)
        s = re.sub(r"\b–±—ã–ª–æ\b\s+(\w+?)(–æ|–∞|–∏)\b", r"\1–ª–∏", s)
        s = re.sub(r"\b–±—É–¥–µ—Ç\b\s+(\w+?)(–æ|–∞|–∏)\b", r"–ø–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è, —á—Ç–æ \1", s)
        # —á—É—Ç—å –≤–∞—Ä—å–∏—Ä—É–µ–º –≤–≤–æ–¥–Ω—ã–µ
        if random.random() < 0.4:
            s = re.sub(r"^([–ê-–Ø–Å].+?)\s+–∑–∞—è–≤–∏–ª[–∞–∏]?,", r"–ü–æ –∏—Ö —Å–ª–æ–≤–∞–º, \1,", s)
        out.append(s)

    res = " ".join(out)
    res = re.sub(r"\s+([,.:;!?])", r"\1", res)
    res = re.sub(r"\s+", " ", res).strip()

    # —Ö–∞—Ä–¥-—Å—Ç–æ–ø: –µ—Å–ª–∏ –≤–¥—Ä—É–≥ –ø–æ–ª—É—á–∏–ª—Å—è —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –ø–æ—Ö–æ–∂–∏–π ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
    if len(res) < len(original)*0.6:
        return original
    return res

# ================== –ú–ê–†–ö–ï–¢–ò–ù–ì–û–í–ê–Ø –ü–û–î–ê–ß–ê ==================
def pick_emoji(text: str) -> str:
    t = (text or "").lower()
    if any(k in t for k in ["–∞–∫—Ü–∏","–∏–Ω–¥–µ–∫—Å","–±–∏—Ä–∂","—Ä—ã–Ω–æ–∫","nasdaq","moex","s&p"]): return "üìà"
    if any(k in t for k in ["–¥–æ–ª–ª–∞—Ä","—Ä—É–±–ª","–≤–∞–ª—é—Ç","–∫—É—Ä—Å","–µ–≤—Ä–æ","—é–∞–Ω—å"]): return "üíµ"
    if any(k in t for k in ["–Ω–µ—Ñ—Ç—å","–≥–∞–∑","opec","–±—Ä–µ–Ω—Ç","—ç–Ω–µ—Ä–≥–∏","lng"]): return "üõ¢Ô∏è"
    if any(k in t for k in ["–∫—Ä–∏–ø—Ç","–±–∏—Ç–∫–æ–∏–Ω","bitcoin","eth","—Å—Ç–µ–π–±–ª","usdt","—Ç–µ–∑–µ—Ä"]): return "ü™ô"
    if any(k in t for k in ["—Å–∞–Ω–∫—Ü","–ø–æ–ª–∏—Ç","–ø–∞—Ä–ª–∞–º–µ–Ω—Ç","–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç","–º–∏–¥","–∫–æ–Ω–≥—Ä–µ—Å—Å","–≤—ã–±–æ—Ä"]): return "üèõÔ∏è"
    if any(k in t for k in ["—Ç–µ—Ö–Ω–æ–ª–æ–≥","–∞–π—Ç–∏","—Å—Ç–∞—Ä—Ç–∞–ø","–∏–Ω–Ω–æ–≤–∞—Ü"]): return "üí°"
    return "üì∞"

def build_sections_marketing(title: str, summary_text: str):
    sents_raw = split_sentences(summary_text)
    sents = dedupe_sentences(sents_raw, title)
    if not sents:
        sents = split_sentences(summary_text)

    lead_sents    = sents[:2] if sents else [title]
    details_sents = sents[2:10] if len(sents) > 2 else []

    # –≤—ã—á–∏—Å—Ç–∏–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
    lead_norm_set = {_normalize_for_cmp(x) for x in lead_sents}
    details_sents = [s for s in details_sents if _normalize_for_cmp(s) not in lead_norm_set]

    # –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∞
    lead_src    = " ".join(lead_sents) or title
    details_src = (" ".join(details_sents)).strip()

    # –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –ø–µ—Ä–µ—Ñ—Ä–∞–∑
    title_p = tidy_paragraph(paraphrase_ru(title, 0.85))
    emoji   = pick_emoji(title + " " + summary_text)

    lead    = tidy_paragraph(f"{emoji} {paraphrase_ru(lead_src, 0.92)}")
    details = tidy_paragraph(paraphrase_ru(details_src, 0.95)) if details_src else ""

    # –µ—Å–ª–∏ –≤–¥—Ä—É–≥ —Å–æ–≤–ø–∞–ª–∏ ‚Äî –¥–æ–∫—Ä—É—Ç–∏–º
    if _normalize_for_cmp(details) == _normalize_for_cmp(lead):
        details = tidy_paragraph(paraphrase_ru(details_src, 0.97))

    # –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π –¥–æ–≤–æ–¥
    t = (title + " " + summary_text).lower()
    if any(k in t for k in ["—Å–æ–∫—Ä–∞—Ç","—É—Ä–µ–∑","–∑–∞–º–æ—Ä–æ–∑","–¥–µ—Ñ–∏—Ü–∏—Ç","—Å–∞–Ω–∫—Ü"]):
        concl = "–ö–æ–Ω—Ç–µ–∫—Å—Ç: –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã —Å–º–µ—â–∞—é—Ç—Å—è –∫ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º –∑–∞–¥–∞—á–∞–º ‚Äî –∂–¥—ë–º –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö —Ä–∞–∑—ä—è—Å–Ω–µ–Ω–∏–π –ø–æ –æ–±—ä—ë–º—É –∏ –∫–∞–ª–µ–Ω–¥–∞—Ä—é –º–µ—Ä."
    elif any(k in t for k in ["—Ä–∞—Å—à–∏—Ä","—É–≤–µ–ª–∏—á","–ø–æ–¥–¥–µ—Ä–∂","–æ–¥–æ–±—Ä","–∏–Ω–≤–µ—Å—Ç","–∑–∞–ø—É—Å—Ç"]):
        concl = "–ö–æ–Ω—Ç–µ–∫—Å—Ç: —à–∞–≥ –¥–æ–±–∞–≤–ª—è–µ—Ç –∏–º–ø—É–ª—å—Å —Ç–µ–º–µ; –º–∞—Å—à—Ç–∞–± –∏ —Å—Ä–æ–∫–∏ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è –æ–ø—Ä–µ–¥–µ–ª—è—Ç —ç—Ñ—Ñ–µ–∫—Ç –¥–ª—è –æ—Ç—Ä–∞—Å–ª–∏."
    elif any(k in t for k in ["—Ä–∏—Å", "–∞–≤–∞—Ä", "—à—Ç–æ—Ä–º", "—Ç–µ—Ä–∞–∫—Ç", "–∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ"]):
        concl = "–ö–æ–Ω—Ç–µ–∫—Å—Ç: –≤ —Ñ–æ–∫—É—Å–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–∞–º–∏ –∏ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è; –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è —É—Ç–æ—á–Ω—è—Ç—Å—è –ø–æ –º–µ—Ä–µ –ø–æ—è–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."
    else:
        concl = "–ö–æ–Ω—Ç–µ–∫—Å—Ç: —Å–ª–µ–¥–∏–º –∑–∞ —Ä–µ–∞–∫—Ü–∏–µ–π —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∏ –ø–æ—Å–ª–µ–¥—É—é—â–∏–º–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ ‚Äî –æ–Ω–∏ –∑–∞–¥–∞–¥—É—Ç —Ç–æ–Ω –Ω–∞ –±–ª–∏–∂–∞–π—à—É—é –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—É."

    return title_p, lead, details, concl

# ================== HTML/–ü–û–î–ü–ò–°–¨ ==================
def html_escape(s: str) -> str:
    return (s or "").replace("&","&amp;").replace("<","&lt;").replace(">","&gt;")

def smart_join_and_trim(paragraphs, max_len=1024):
    raw = "\n\n".join([p for p in paragraphs if p])
    if len(raw) <= max_len: return raw
    cut = raw[:max_len]
    for sep in [". ", "! ", "? ", "‚Ä¶ ", ".\n", "!\n", "?\n", "‚Ä¶\n"]:
        pos = cut.rfind(sep)
        if pos != -1: return cut[:pos+1].rstrip()
    return cut[:-1].rstrip() + "‚Ä¶"

def build_full_caption(title, lead, details, conclusion, link, hidden_tags):
    dom = (re.sub(r"^www\.", "", (link or "").split("/")[2]) if link else "–∏—Å—Ç–æ—á–Ω–∏–∫")
    title_html = f"<b>{html_escape(title)}</b>"

    body = [
        html_escape(lead),
        f"<b>–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏:</b>\n{html_escape(details)}" if details else "",
        f"<b>–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç:</b>\n{html_escape(conclusion)}"
    ]
    body_text = smart_join_and_trim(body, max_len=1024-220)

    footer = [
        f'–ò—Å—Ç–æ—á–Ω–∏–∫: <a href="{html_escape(link)}">{html_escape(dom)}</a>',
        f'ü™ô <a href="https://t.me/{CHANNEL_ID.lstrip("@")}">USDT=Dollar</a>'
    ]
    caption = f"{title_html}\n\n{body_text}\n\n" + "\n".join(footer)

    if hidden_tags:
        inner = hidden_tags.strip("|")
        spoiler = f'\n\n<span class="tg-spoiler">{html_escape(inner)}</span>'
        if len(caption + spoiler) <= 1024:
            return caption + spoiler
    return caption[:1024]

# ================== –û–¢–ü–†–ê–í–ö–ê ==================
def send_photo_with_caption(photo_bytes: io.BytesIO, caption: str):
    if not BOT_TOKEN: raise RuntimeError("BOT_TOKEN –Ω–µ –∑–∞–¥–∞–Ω")
    if not CHANNEL_ID or not CHANNEL_ID.startswith("@"):
        raise RuntimeError("CHANNEL_ID –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ @–∏–º—è_–∫–∞–Ω–∞–ª–∞")
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendPhoto"
    files = {"photo": ("cover.png", photo_bytes, "image/png")}
    data  = {"chat_id": CHANNEL_ID, "caption": caption, "parse_mode": "HTML"}
    r = requests.post(url, files=files, data=data, timeout=HTTP_TIMEOUT)
    print("Telegram sendPhoto:", r.status_code, r.text[:180])
    r.raise_for_status()

# ================== –ü–û–¢–û–ö ==================
def _process_entries(entries, state, posted_uids, batch_seen, now, posted):
    for e in entries:
        if posted[0] >= MAX_POSTS_PER_RUN:
            break

        title   = (getattr(e, "title", "") or "").strip()
        summary = (getattr(e, "summary", getattr(e, "description", "")) or "").strip()
        link    = (getattr(e, "link", "") or "").strip()

        if detect_lang(title + " " + summary) != "ru":
            continue

        uid = _uid_for(link, title)
        if uid in posted_uids or uid in batch_seen:
            continue

        title_p, lead, details, concl = build_sections_marketing(title, summary)
        body_len = len((lead + " " + details + " " + concl).strip())
        if body_len < LOW_QUALITY_MIN_LEN:
            print("Skip low-quality item:", title[:90]); continue

        domain = re.sub(r"^www\.", "", link.split("/")[2]) if link else "source"
        themed_hint = (title + " " + summary)
        card   = draw_card(title_p, domain, now, themed_hint=themed_hint)
        hidden = extract_tags_source(title + " " + summary, 3, 5)
        caption = build_full_caption(title_p, lead, details, concl, link, hidden)

        try:
            send_photo_with_caption(card, caption)
            posted[0] += 1
            batch_seen.add(uid)
            posted_uids.add(uid)
            state["posted"] = list(posted_uids)[-5000:]
            _save_state(state)
            time.sleep(1.0)
        except Exception as ex:
            print("Error sending:", ex)

def main():
    state = _load_state()
    posted_uids = set(state.get("posted", []))
    batch_seen  = set()
    posted = [0]
    now = datetime.now().strftime("%d.%m %H:%M")

    for feed_url in RSS_FEEDS:
        try:
            fp = feedparser.parse(feed_url)
        except Exception as e:
            print("Feed error:", feed_url, e); continue
        _process_entries(fp.entries, state, posted_uids, batch_seen, now, posted)
        if posted[0] >= MAX_POSTS_PER_RUN:
            break

    if posted[0] == 0 and ALLOW_BACKLOG:
        print("No fresh posts. Trying backlog mode...")
        for feed_url in RSS_FEEDS:
            try:
                fp = feedparser.parse(feed_url)
            except Exception as e:
                print("Feed error:", feed_url, e); continue
            _process_entries(fp.entries, state, posted_uids, batch_seen, now, posted)
            if posted[0] >= MAX_POSTS_PER_RUN:
                break

    if posted[0] == 0:
        print("Nothing to post.")

if __name__ == "__main__":
    main()
